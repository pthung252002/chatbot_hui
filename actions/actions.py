from rasa_sdk import Action, Tracker
from rasa_sdk.events import SlotSet
from rasa_sdk.executor import CollectingDispatcher
from typing import Any, Text, Dict, List
from langchain.chat_models import ChatOpenAI
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
import os
import traceback

# Danh s√°ch API key t·ª´ OpenRouter ƒë·ªÉ thay khi h·∫øt token
API_KEYS = [
]

# Khai b√°o chung
embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vectorstore = FAISS.load_local("vector_db", embedding)

custom_prompt_template = """S·ª≠ d·ª•ng th√¥ng tin d∆∞·ªõi ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.

- N·∫øu b·∫°n kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi, h√£y n√≥i l√† b·∫°n kh√¥ng bi·∫øt v√† nh·ªù ng∆∞·ªùi d√πng ƒë·∫∑t l·∫°i c√¢u h·ªèi r√µ r√†ng h∆°n, ƒë·ª´ng b·ªãa ra c√¢u tr·∫£ l·ªùi.
- T·∫•t c·∫£ c√¢u tr·∫£ l·ªùi PH·∫¢I ƒë∆∞·ª£c vi·∫øt b·∫±ng ti·∫øng Vi·ªát.
- C√¢u tr·∫£ l·ªùi PH·∫¢I bao g·ªìm ƒë·∫ßy ƒë·ªß c√°c b∆∞·ªõc h∆∞·ªõng d·∫´n, k√®m theo **m·ªçi th√¥ng tin li√™n quan xu·∫•t hi·ªán sau c√°c b∆∞·ªõc**, ƒë·∫∑c bi·ªát l√† **h√¨nh ·∫£nh minh h·ªça (<img>)** v√† **video h∆∞·ªõng d·∫´n (<iframe>)** N·∫æU C√ì.
- KH√îNG ƒë∆∞·ª£c b·ªãa ra b·∫•t k·ª≥ th√¥ng tin n√†o n·∫øu kh√¥ng c√≥ trong context.
- C√¢u tr·∫£ l·ªùi PH·∫¢I ƒë∆∞·ª£c ƒë·ªãnh d·∫°ng b·∫±ng HTML ƒë∆°n gi·∫£n: <p>, <b>, <ul>, <li>, <br>. KH√îNG d√πng markdown ho·∫∑c c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát.
- Lu√¥n x∆∞ng h√¥ l√† "Em" v√† g·ªçi ng∆∞·ªùi d√πng l√† "Anh/Ch·ªã".

Context: {context}
Question: {question}
"""

custom_prompt = PromptTemplate(
    template=custom_prompt_template,
    input_variables=["context", "question"]
)

def create_llm(api_key: str):
    return ChatOpenAI(
        model_name="nvidia/llama-3.1-nemotron-ultra-253b-v1:free",  # ho·∫∑c model b·∫°n mu·ªën
        temperature=0,
        openai_api_key=api_key,
        openai_api_base="https://openrouter.ai/api/v1",
        request_timeout=15  # gi·ªõi h·∫°n t·ªëi ƒëa 15 gi√¢y
    )

# H√†m ƒë·ªÉ reset slot sau khi cang c·∫•p c√°c h∆∞·ªõng d·∫´n
class ActionResetSlots(Action):
    def name(self):
        return "action_reset_slots"

    def run(self, dispatcher, tracker, domain):
        return [
            SlotSet("hoat_dong_chinh", None),
            SlotSet("hoat_dong_phu", None),
            SlotSet("doi_tuong", None),
            SlotSet("doi_tuong_phu", None),
            SlotSet("trang_thai", None),
            SlotSet("tro_tu", None),
            SlotSet("tro_tu2", None)
        ]
class ActionProvideGuide(Action):

    def name(self) -> Text:
        return "action_provide_guide"

    def run(self, dispatcher: CollectingDispatcher,
            tracker: Tracker,
            domain: Dict[Text, Any]) -> List[Dict[Text, Any]]:

        user_question = tracker.latest_message.get("text")
        print(f"** C√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng: {user_question}")

        answer = "Xin l·ªói, ƒë√£ c√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω c√¢u h·ªèi c·ªßa b·∫°n."

        for api_key in API_KEYS:
            try:
                print(f"ƒêang th·ª≠ key: {api_key[:15]}...")
                llm = create_llm(api_key)
                qa_chain = RetrievalQA.from_chain_type(
                    llm=llm,
                    retriever=vectorstore.as_retriever(),
                    chain_type="stuff",
                    chain_type_kwargs={"prompt": custom_prompt},
                    return_source_documents=True
                )
                result = qa_chain({"query": user_question})
                answer = result["result"]

                print(f"D√πng key {api_key[:15]}... th√†nh c√¥ng!")
                #for doc in result["source_documents"]:
                    #print("üìÑ Chunk:\n", doc.page_content[:1000])
                break  # Th√†nh c√¥ng th√¨ d·ª´ng th·ª≠ key ti·∫øp theo

            except Exception as e:
                print(f"Key {api_key[:15]}... l·ªói: {str(e)}")
                print(traceback.format_exc())
                continue

        dispatcher.utter_message(json_message={"html": answer})
        return []

class ActionAnswerDuration(Action):
    def name(self) -> Text:
        return "action_answer_duration"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[Text, Any]) -> List[Dict[Text, Any]]:

        user_question = tracker.latest_message.get("text")
        print(f"** C√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng: {user_question}")

        answer = "Xin l·ªói, ƒë√£ c√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω c√¢u h·ªèi c·ªßa b·∫°n."

        for api_key in API_KEYS:
            try:
                print(f"ƒêang th·ª≠ key: {api_key[:15]}...")
                llm = create_llm(api_key)
                qa_chain = RetrievalQA.from_chain_type(
                    llm=llm,
                    retriever=vectorstore.as_retriever(),
                    chain_type="stuff",
                    chain_type_kwargs={"prompt": custom_prompt},
                    return_source_documents=True
                )
                result = qa_chain({"query": user_question})
                answer = result["result"]

                print(f"D√πng key {api_key[:15]}... th√†nh c√¥ng!")
                #for doc in result["source_documents"]:
                    #print("üìÑ Chunk:\n", doc.page_content[:1000])
                break  # Th√†nh c√¥ng th√¨ d·ª´ng th·ª≠ key ti·∫øp theo

            except Exception as e:
                print(f"Key {api_key[:15]}... l·ªói: {str(e)}")
                print(traceback.format_exc())
                continue

        dispatcher.utter_message(json_message={"html": answer})
        return []
